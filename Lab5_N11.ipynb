{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data and create DataFrame from it\n",
    "data = pd.read_csv('11.csv', sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>area</th>\n",
       "      <th>class</th>\n",
       "      <th>gray_Mean</th>\n",
       "      <th>gray_Variance</th>\n",
       "      <th>gray_Skewness</th>\n",
       "      <th>gray_Kurtosis</th>\n",
       "      <th>gray_Perc.01%</th>\n",
       "      <th>gray_Perc.10%</th>\n",
       "      <th>...</th>\n",
       "      <th>b_S(5,-5)SumVarnc</th>\n",
       "      <th>b_S(5,-5)SumEntrp</th>\n",
       "      <th>b_S(5,-5)Entropy</th>\n",
       "      <th>b_S(5,-5)DifVarnc</th>\n",
       "      <th>b_S(5,-5)DifEntrp</th>\n",
       "      <th>b_GrMean</th>\n",
       "      <th>b_GrVariance</th>\n",
       "      <th>b_GrSkewness</th>\n",
       "      <th>b_GrKurtosis</th>\n",
       "      <th>b_GrNonZeros</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>436697</td>\n",
       "      <td>22-Dec-2016 13-43-41</td>\n",
       "      <td>100</td>\n",
       "      <td>DZN</td>\n",
       "      <td>75.54</td>\n",
       "      <td>8.2884</td>\n",
       "      <td>-0.393290</td>\n",
       "      <td>-0.656038</td>\n",
       "      <td>68.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2901.143532</td>\n",
       "      <td>0.913105</td>\n",
       "      <td>1.420585</td>\n",
       "      <td>29.100282</td>\n",
       "      <td>0.867934</td>\n",
       "      <td>2.760527</td>\n",
       "      <td>2.676367</td>\n",
       "      <td>0.334689</td>\n",
       "      <td>-0.004993</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>436698</td>\n",
       "      <td>22-Dec-2016 13-43-41</td>\n",
       "      <td>100</td>\n",
       "      <td>DZN</td>\n",
       "      <td>67.59</td>\n",
       "      <td>14.0819</td>\n",
       "      <td>-0.367885</td>\n",
       "      <td>-1.074752</td>\n",
       "      <td>60.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2228.018342</td>\n",
       "      <td>0.950978</td>\n",
       "      <td>1.391802</td>\n",
       "      <td>6.977909</td>\n",
       "      <td>0.711356</td>\n",
       "      <td>3.481352</td>\n",
       "      <td>2.755186</td>\n",
       "      <td>-0.166114</td>\n",
       "      <td>-0.695810</td>\n",
       "      <td>0.953125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>436699</td>\n",
       "      <td>22-Dec-2016 13-43-41</td>\n",
       "      <td>100</td>\n",
       "      <td>DZN</td>\n",
       "      <td>60.86</td>\n",
       "      <td>5.3404</td>\n",
       "      <td>0.360231</td>\n",
       "      <td>-0.899669</td>\n",
       "      <td>57.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1910.459716</td>\n",
       "      <td>0.757815</td>\n",
       "      <td>1.315165</td>\n",
       "      <td>18.677696</td>\n",
       "      <td>0.819770</td>\n",
       "      <td>2.808814</td>\n",
       "      <td>2.735563</td>\n",
       "      <td>1.045370</td>\n",
       "      <td>1.092342</td>\n",
       "      <td>0.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>436700</td>\n",
       "      <td>22-Dec-2016 13-43-41</td>\n",
       "      <td>100</td>\n",
       "      <td>DZN</td>\n",
       "      <td>60.32</td>\n",
       "      <td>60.9776</td>\n",
       "      <td>-0.748717</td>\n",
       "      <td>-0.873833</td>\n",
       "      <td>44.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1700.315300</td>\n",
       "      <td>1.113652</td>\n",
       "      <td>1.626723</td>\n",
       "      <td>38.558999</td>\n",
       "      <td>1.015338</td>\n",
       "      <td>5.149898</td>\n",
       "      <td>6.853554</td>\n",
       "      <td>0.669685</td>\n",
       "      <td>-0.053380</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>436701</td>\n",
       "      <td>22-Dec-2016 13-43-41</td>\n",
       "      <td>100</td>\n",
       "      <td>DZN</td>\n",
       "      <td>75.00</td>\n",
       "      <td>5.2200</td>\n",
       "      <td>-0.090556</td>\n",
       "      <td>-0.474347</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2860.139183</td>\n",
       "      <td>0.738433</td>\n",
       "      <td>1.300173</td>\n",
       "      <td>16.376975</td>\n",
       "      <td>0.858845</td>\n",
       "      <td>2.469800</td>\n",
       "      <td>1.993839</td>\n",
       "      <td>0.061216</td>\n",
       "      <td>-0.683562</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 940 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                  name  area class  gray_Mean  gray_Variance  \\\n",
       "0      436697  22-Dec-2016 13-43-41   100   DZN      75.54         8.2884   \n",
       "1      436698  22-Dec-2016 13-43-41   100   DZN      67.59        14.0819   \n",
       "2      436699  22-Dec-2016 13-43-41   100   DZN      60.86         5.3404   \n",
       "3      436700  22-Dec-2016 13-43-41   100   DZN      60.32        60.9776   \n",
       "4      436701  22-Dec-2016 13-43-41   100   DZN      75.00         5.2200   \n",
       "\n",
       "   gray_Skewness  gray_Kurtosis  gray_Perc.01%  gray_Perc.10%      ...       \\\n",
       "0      -0.393290      -0.656038           68.0           71.0      ...        \n",
       "1      -0.367885      -1.074752           60.0           62.0      ...        \n",
       "2       0.360231      -0.899669           57.0           58.0      ...        \n",
       "3      -0.748717      -0.873833           44.0           47.0      ...        \n",
       "4      -0.090556      -0.474347           70.0           71.0      ...        \n",
       "\n",
       "   b_S(5,-5)SumVarnc  b_S(5,-5)SumEntrp  b_S(5,-5)Entropy  b_S(5,-5)DifVarnc  \\\n",
       "0        2901.143532           0.913105          1.420585          29.100282   \n",
       "1        2228.018342           0.950978          1.391802           6.977909   \n",
       "2        1910.459716           0.757815          1.315165          18.677696   \n",
       "3        1700.315300           1.113652          1.626723          38.558999   \n",
       "4        2860.139183           0.738433          1.300173          16.376975   \n",
       "\n",
       "   b_S(5,-5)DifEntrp  b_GrMean  b_GrVariance  b_GrSkewness  b_GrKurtosis  \\\n",
       "0           0.867934  2.760527      2.676367      0.334689     -0.004993   \n",
       "1           0.711356  3.481352      2.755186     -0.166114     -0.695810   \n",
       "2           0.819770  2.808814      2.735563      1.045370      1.092342   \n",
       "3           1.015338  5.149898      6.853554      0.669685     -0.053380   \n",
       "4           0.858845  2.469800      1.993839      0.061216     -0.683562   \n",
       "\n",
       "   b_GrNonZeros  \n",
       "0      0.906250  \n",
       "1      0.953125  \n",
       "2      0.984375  \n",
       "3      1.000000  \n",
       "4      0.906250  \n",
       "\n",
       "[5 rows x 940 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22-Dec-2016 13-43-41</td>\n",
       "      <td>DZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22-Dec-2016 13-43-41</td>\n",
       "      <td>DZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22-Dec-2016 13-43-41</td>\n",
       "      <td>DZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22-Dec-2016 13-43-41</td>\n",
       "      <td>DZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22-Dec-2016 13-43-41</td>\n",
       "      <td>DZN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name class\n",
       "0  22-Dec-2016 13-43-41   DZN\n",
       "1  22-Dec-2016 13-43-41   DZN\n",
       "2  22-Dec-2016 13-43-41   DZN\n",
       "3  22-Dec-2016 13-43-41   DZN\n",
       "4  22-Dec-2016 13-43-41   DZN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['name', 'class']].head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('name', axis=1)\n",
    "Y = data.loc[:, data.columns == 'class']\n",
    "X = data.loc[:, data.columns != 'class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DZN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class\n",
       "0   DZN\n",
       "1   DZN\n",
       "2   DZN\n",
       "3   DZN\n",
       "4   DZN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>area</th>\n",
       "      <th>gray_Mean</th>\n",
       "      <th>gray_Variance</th>\n",
       "      <th>gray_Skewness</th>\n",
       "      <th>gray_Kurtosis</th>\n",
       "      <th>gray_Perc.01%</th>\n",
       "      <th>gray_Perc.10%</th>\n",
       "      <th>gray_Perc.50%</th>\n",
       "      <th>gray_Perc.90%</th>\n",
       "      <th>...</th>\n",
       "      <th>b_S(5,-5)SumVarnc</th>\n",
       "      <th>b_S(5,-5)SumEntrp</th>\n",
       "      <th>b_S(5,-5)Entropy</th>\n",
       "      <th>b_S(5,-5)DifVarnc</th>\n",
       "      <th>b_S(5,-5)DifEntrp</th>\n",
       "      <th>b_GrMean</th>\n",
       "      <th>b_GrVariance</th>\n",
       "      <th>b_GrSkewness</th>\n",
       "      <th>b_GrKurtosis</th>\n",
       "      <th>b_GrNonZeros</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>436697</td>\n",
       "      <td>100</td>\n",
       "      <td>75.54</td>\n",
       "      <td>8.2884</td>\n",
       "      <td>-0.393290</td>\n",
       "      <td>-0.656038</td>\n",
       "      <td>68.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2901.143532</td>\n",
       "      <td>0.913105</td>\n",
       "      <td>1.420585</td>\n",
       "      <td>29.100282</td>\n",
       "      <td>0.867934</td>\n",
       "      <td>2.760527</td>\n",
       "      <td>2.676367</td>\n",
       "      <td>0.334689</td>\n",
       "      <td>-0.004993</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>436698</td>\n",
       "      <td>100</td>\n",
       "      <td>67.59</td>\n",
       "      <td>14.0819</td>\n",
       "      <td>-0.367885</td>\n",
       "      <td>-1.074752</td>\n",
       "      <td>60.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2228.018342</td>\n",
       "      <td>0.950978</td>\n",
       "      <td>1.391802</td>\n",
       "      <td>6.977909</td>\n",
       "      <td>0.711356</td>\n",
       "      <td>3.481352</td>\n",
       "      <td>2.755186</td>\n",
       "      <td>-0.166114</td>\n",
       "      <td>-0.695810</td>\n",
       "      <td>0.953125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>436699</td>\n",
       "      <td>100</td>\n",
       "      <td>60.86</td>\n",
       "      <td>5.3404</td>\n",
       "      <td>0.360231</td>\n",
       "      <td>-0.899669</td>\n",
       "      <td>57.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1910.459716</td>\n",
       "      <td>0.757815</td>\n",
       "      <td>1.315165</td>\n",
       "      <td>18.677696</td>\n",
       "      <td>0.819770</td>\n",
       "      <td>2.808814</td>\n",
       "      <td>2.735563</td>\n",
       "      <td>1.045370</td>\n",
       "      <td>1.092342</td>\n",
       "      <td>0.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>436700</td>\n",
       "      <td>100</td>\n",
       "      <td>60.32</td>\n",
       "      <td>60.9776</td>\n",
       "      <td>-0.748717</td>\n",
       "      <td>-0.873833</td>\n",
       "      <td>44.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1700.315300</td>\n",
       "      <td>1.113652</td>\n",
       "      <td>1.626723</td>\n",
       "      <td>38.558999</td>\n",
       "      <td>1.015338</td>\n",
       "      <td>5.149898</td>\n",
       "      <td>6.853554</td>\n",
       "      <td>0.669685</td>\n",
       "      <td>-0.053380</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>436701</td>\n",
       "      <td>100</td>\n",
       "      <td>75.00</td>\n",
       "      <td>5.2200</td>\n",
       "      <td>-0.090556</td>\n",
       "      <td>-0.474347</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2860.139183</td>\n",
       "      <td>0.738433</td>\n",
       "      <td>1.300173</td>\n",
       "      <td>16.376975</td>\n",
       "      <td>0.858845</td>\n",
       "      <td>2.469800</td>\n",
       "      <td>1.993839</td>\n",
       "      <td>0.061216</td>\n",
       "      <td>-0.683562</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 938 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  area  gray_Mean  gray_Variance  gray_Skewness  gray_Kurtosis  \\\n",
       "0      436697   100      75.54         8.2884      -0.393290      -0.656038   \n",
       "1      436698   100      67.59        14.0819      -0.367885      -1.074752   \n",
       "2      436699   100      60.86         5.3404       0.360231      -0.899669   \n",
       "3      436700   100      60.32        60.9776      -0.748717      -0.873833   \n",
       "4      436701   100      75.00         5.2200      -0.090556      -0.474347   \n",
       "\n",
       "   gray_Perc.01%  gray_Perc.10%  gray_Perc.50%  gray_Perc.90%      ...       \\\n",
       "0           68.0           71.0           77.0           80.0      ...        \n",
       "1           60.0           62.0           68.0           71.0      ...        \n",
       "2           57.0           58.0           61.0           64.0      ...        \n",
       "3           44.0           47.0           64.0           68.0      ...        \n",
       "4           70.0           71.0           75.0           78.0      ...        \n",
       "\n",
       "   b_S(5,-5)SumVarnc  b_S(5,-5)SumEntrp  b_S(5,-5)Entropy  b_S(5,-5)DifVarnc  \\\n",
       "0        2901.143532           0.913105          1.420585          29.100282   \n",
       "1        2228.018342           0.950978          1.391802           6.977909   \n",
       "2        1910.459716           0.757815          1.315165          18.677696   \n",
       "3        1700.315300           1.113652          1.626723          38.558999   \n",
       "4        2860.139183           0.738433          1.300173          16.376975   \n",
       "\n",
       "   b_S(5,-5)DifEntrp  b_GrMean  b_GrVariance  b_GrSkewness  b_GrKurtosis  \\\n",
       "0           0.867934  2.760527      2.676367      0.334689     -0.004993   \n",
       "1           0.711356  3.481352      2.755186     -0.166114     -0.695810   \n",
       "2           0.819770  2.808814      2.735563      1.045370      1.092342   \n",
       "3           1.015338  5.149898      6.853554      0.669685     -0.053380   \n",
       "4           0.858845  2.469800      1.993839      0.061216     -0.683562   \n",
       "\n",
       "   b_GrNonZeros  \n",
       "0      0.906250  \n",
       "1      0.953125  \n",
       "2      0.984375  \n",
       "3      1.000000  \n",
       "4      0.906250  \n",
       "\n",
       "[5 rows x 938 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>area</th>\n",
       "      <th>gray_Mean</th>\n",
       "      <th>gray_Variance</th>\n",
       "      <th>gray_Skewness</th>\n",
       "      <th>gray_Kurtosis</th>\n",
       "      <th>gray_Perc.01%</th>\n",
       "      <th>gray_Perc.10%</th>\n",
       "      <th>gray_Perc.50%</th>\n",
       "      <th>gray_Perc.90%</th>\n",
       "      <th>...</th>\n",
       "      <th>b_S(5,-5)SumVarnc</th>\n",
       "      <th>b_S(5,-5)SumEntrp</th>\n",
       "      <th>b_S(5,-5)Entropy</th>\n",
       "      <th>b_S(5,-5)DifVarnc</th>\n",
       "      <th>b_S(5,-5)DifEntrp</th>\n",
       "      <th>b_GrMean</th>\n",
       "      <th>b_GrVariance</th>\n",
       "      <th>b_GrSkewness</th>\n",
       "      <th>b_GrKurtosis</th>\n",
       "      <th>b_GrNonZeros</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>443224.500000</td>\n",
       "      <td>150.585784</td>\n",
       "      <td>96.254364</td>\n",
       "      <td>129.296636</td>\n",
       "      <td>-0.017162</td>\n",
       "      <td>0.280239</td>\n",
       "      <td>79.171262</td>\n",
       "      <td>85.588542</td>\n",
       "      <td>96.884344</td>\n",
       "      <td>105.803385</td>\n",
       "      <td>...</td>\n",
       "      <td>7583.373416</td>\n",
       "      <td>1.117667</td>\n",
       "      <td>1.674840</td>\n",
       "      <td>75.329206</td>\n",
       "      <td>0.946017</td>\n",
       "      <td>4.539982</td>\n",
       "      <td>7.800437</td>\n",
       "      <td>0.538672</td>\n",
       "      <td>0.076441</td>\n",
       "      <td>0.971969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3769.086892</td>\n",
       "      <td>54.714008</td>\n",
       "      <td>56.117444</td>\n",
       "      <td>266.620494</td>\n",
       "      <td>0.898016</td>\n",
       "      <td>2.438761</td>\n",
       "      <td>42.945108</td>\n",
       "      <td>48.626013</td>\n",
       "      <td>58.087830</td>\n",
       "      <td>61.667222</td>\n",
       "      <td>...</td>\n",
       "      <td>10411.572775</td>\n",
       "      <td>0.201292</td>\n",
       "      <td>0.227815</td>\n",
       "      <td>151.173722</td>\n",
       "      <td>0.195632</td>\n",
       "      <td>2.058940</td>\n",
       "      <td>10.905071</td>\n",
       "      <td>0.369186</td>\n",
       "      <td>1.011380</td>\n",
       "      <td>0.024650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>436697.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>34.630000</td>\n",
       "      <td>0.641900</td>\n",
       "      <td>-5.099406</td>\n",
       "      <td>-1.662739</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>21.886866</td>\n",
       "      <td>0.519481</td>\n",
       "      <td>0.929611</td>\n",
       "      <td>1.919168</td>\n",
       "      <td>0.442268</td>\n",
       "      <td>1.558813</td>\n",
       "      <td>0.570103</td>\n",
       "      <td>-0.589856</td>\n",
       "      <td>-1.458017</td>\n",
       "      <td>0.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>439960.750000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>54.239028</td>\n",
       "      <td>7.767127</td>\n",
       "      <td>-0.381784</td>\n",
       "      <td>-0.792883</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>693.818202</td>\n",
       "      <td>0.979165</td>\n",
       "      <td>1.518797</td>\n",
       "      <td>9.965087</td>\n",
       "      <td>0.802260</td>\n",
       "      <td>3.235369</td>\n",
       "      <td>3.053082</td>\n",
       "      <td>0.293227</td>\n",
       "      <td>-0.523740</td>\n",
       "      <td>0.958678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>443224.500000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>73.181187</td>\n",
       "      <td>20.001458</td>\n",
       "      <td>0.027967</td>\n",
       "      <td>-0.352191</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2427.906559</td>\n",
       "      <td>1.072661</td>\n",
       "      <td>1.648122</td>\n",
       "      <td>18.136813</td>\n",
       "      <td>0.900519</td>\n",
       "      <td>3.748919</td>\n",
       "      <td>4.047057</td>\n",
       "      <td>0.503083</td>\n",
       "      <td>-0.153380</td>\n",
       "      <td>0.975309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>446488.250000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>131.255682</td>\n",
       "      <td>73.262298</td>\n",
       "      <td>0.468372</td>\n",
       "      <td>0.338408</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11552.331860</td>\n",
       "      <td>1.221447</td>\n",
       "      <td>1.807004</td>\n",
       "      <td>58.661337</td>\n",
       "      <td>1.060938</td>\n",
       "      <td>5.087449</td>\n",
       "      <td>8.482724</td>\n",
       "      <td>0.733595</td>\n",
       "      <td>0.361828</td>\n",
       "      <td>0.988616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>449752.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>223.190000</td>\n",
       "      <td>1992.576737</td>\n",
       "      <td>4.031808</td>\n",
       "      <td>32.434843</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>52788.693309</td>\n",
       "      <td>1.873434</td>\n",
       "      <td>2.571574</td>\n",
       "      <td>1951.656937</td>\n",
       "      <td>1.650623</td>\n",
       "      <td>17.685676</td>\n",
       "      <td>172.929845</td>\n",
       "      <td>3.266544</td>\n",
       "      <td>15.479892</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 938 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0          area     gray_Mean  gray_Variance  \\\n",
       "count   13056.000000  13056.000000  13056.000000   13056.000000   \n",
       "mean   443224.500000    150.585784     96.254364     129.296636   \n",
       "std      3769.086892     54.714008     56.117444     266.620494   \n",
       "min    436697.000000    100.000000     34.630000       0.641900   \n",
       "25%    439960.750000    100.000000     54.239028       7.767127   \n",
       "50%    443224.500000    121.000000     73.181187      20.001458   \n",
       "75%    446488.250000    169.000000    131.255682      73.262298   \n",
       "max    449752.000000    400.000000    223.190000    1992.576737   \n",
       "\n",
       "       gray_Skewness  gray_Kurtosis  gray_Perc.01%  gray_Perc.10%  \\\n",
       "count   13056.000000   13056.000000   13056.000000   13056.000000   \n",
       "mean       -0.017162       0.280239      79.171262      85.588542   \n",
       "std         0.898016       2.438761      42.945108      48.626013   \n",
       "min        -5.099406      -1.662739      31.000000      33.000000   \n",
       "25%        -0.381784      -0.792883      48.000000      50.000000   \n",
       "50%         0.027967      -0.352191      65.000000      68.000000   \n",
       "75%         0.468372       0.338408     101.000000     112.000000   \n",
       "max         4.031808      32.434843     219.000000     220.000000   \n",
       "\n",
       "       gray_Perc.50%  gray_Perc.90%      ...       b_S(5,-5)SumVarnc  \\\n",
       "count   13056.000000   13056.000000      ...            13056.000000   \n",
       "mean       96.884344     105.803385      ...             7583.373416   \n",
       "std        58.087830      61.667222      ...            10411.572775   \n",
       "min        34.000000      37.000000      ...               21.886866   \n",
       "25%        54.000000      60.000000      ...              693.818202   \n",
       "50%        73.000000      79.000000      ...             2427.906559   \n",
       "75%       132.000000     147.000000      ...            11552.331860   \n",
       "max       223.000000     231.000000      ...            52788.693309   \n",
       "\n",
       "       b_S(5,-5)SumEntrp  b_S(5,-5)Entropy  b_S(5,-5)DifVarnc  \\\n",
       "count       13056.000000      13056.000000       13056.000000   \n",
       "mean            1.117667          1.674840          75.329206   \n",
       "std             0.201292          0.227815         151.173722   \n",
       "min             0.519481          0.929611           1.919168   \n",
       "25%             0.979165          1.518797           9.965087   \n",
       "50%             1.072661          1.648122          18.136813   \n",
       "75%             1.221447          1.807004          58.661337   \n",
       "max             1.873434          2.571574        1951.656937   \n",
       "\n",
       "       b_S(5,-5)DifEntrp      b_GrMean  b_GrVariance  b_GrSkewness  \\\n",
       "count       13056.000000  13056.000000  13056.000000  13056.000000   \n",
       "mean            0.946017      4.539982      7.800437      0.538672   \n",
       "std             0.195632      2.058940     10.905071      0.369186   \n",
       "min             0.442268      1.558813      0.570103     -0.589856   \n",
       "25%             0.802260      3.235369      3.053082      0.293227   \n",
       "50%             0.900519      3.748919      4.047057      0.503083   \n",
       "75%             1.060938      5.087449      8.482724      0.733595   \n",
       "max             1.650623     17.685676    172.929845      3.266544   \n",
       "\n",
       "       b_GrKurtosis  b_GrNonZeros  \n",
       "count  13056.000000  13056.000000  \n",
       "mean       0.076441      0.971969  \n",
       "std        1.011380      0.024650  \n",
       "min       -1.458017      0.828125  \n",
       "25%       -0.523740      0.958678  \n",
       "50%       -0.153380      0.975309  \n",
       "75%        0.361828      0.988616  \n",
       "max       15.479892      1.000000  \n",
       "\n",
       "[8 rows x 938 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>DZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        class\n",
       "count   13056\n",
       "unique      5\n",
       "top       DZN\n",
       "freq     3252"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Заметим, что у нас 5 уникальных классов. 5 + май = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'area', 'gray_Mean', 'gray_Variance', 'gray_Skewness',\n",
       "       'gray_Kurtosis', 'gray_Perc.01%', 'gray_Perc.10%', 'gray_Perc.50%',\n",
       "       'gray_Perc.90%',\n",
       "       ...\n",
       "       'b_S(5,-5)SumVarnc', 'b_S(5,-5)SumEntrp', 'b_S(5,-5)Entropy',\n",
       "       'b_S(5,-5)DifVarnc', 'b_S(5,-5)DifEntrp', 'b_GrMean', 'b_GrVariance',\n",
       "       'b_GrSkewness', 'b_GrKurtosis', 'b_GrNonZeros'],\n",
       "      dtype='object', length=938)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Списки признаков\n",
    "xETC = X.loc[:, ['g_S(3,-3)SumAverg','b_S(1,0)SumVarnc','r_S(4,-4)SumVarnc','b_Mean','g_S(0,4)SumAverg','gray_S(5,-5)SumAverg','g_S(0,3)SumVarnc','b_S(0,2)SumOfSqs','b_S(3,0)SumVarnc','r_S(1,1)SumVarnc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DZN', 'HardExudates', 'Makula', 'Otek', 'Vessels'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = data['class'].unique()\n",
    "labels = []\n",
    "for j in range(len(X)):\n",
    "    for p in range(len(classes)):\n",
    "        if Y.iloc[j].values==classes[p]:\n",
    "            labels.append(p)\n",
    "classes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/theano/configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import theano as th\n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some useful utilities for creating main components of the perceptron\n",
    "\n",
    "def init_weights(D, H):\n",
    "    # D - input dimension\n",
    "    # H - outputs dimension, i.e. number of neurons\n",
    "    W = np.random.randn(D, H) / np.sqrt(D)\n",
    "    b = np.zeros(H)\n",
    "    \n",
    "    W = th.shared(W)\n",
    "    b = th.shared(b)\n",
    "    return W, b\n",
    "    \n",
    "\n",
    "def create_layer(x, W, b, activation=T.tanh):\n",
    "    # In this example we're going to use hyperbolic tangent\n",
    "    # as an activation function, but you can use other ones.\n",
    "    # We encourage you to do so because activation\n",
    "    # has a great influence on the accuracy of the model.\n",
    "    x = T.dot(x, W) + b\n",
    "    if activation is not None:\n",
    "        x = activation(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2 layers\n",
    "x = T.vector('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1, b1 = init_weights(D=938, H=350)\n",
    "out_l1 = create_layer(x, W1, b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The second (classification) layer with 5 neurons because we have 5 classes\n",
    "W2, b2 = init_weights(D=350, H=5)\n",
    "out_l2 = create_layer(out_l1, W2, b2, activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classification_out = T.nnet.softmax(out_l2)\n",
    "\n",
    "# Define softmat output as Theano function so that we can\n",
    "# use it later\n",
    "softmax_out = th.function(\n",
    "    inputs=[x],\n",
    "    outputs=classification_out\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_out(xETC.iloc[1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative log-likelihood\n",
    "loss = -T.log(classification_out + 1e-13) # add small constant for numerical stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = T.scalar('y', dtype=T.int32) # Class index must be an integer\n",
    "\n",
    "class_loss = loss[0, label] # Don't forget it was a matrix\n",
    "\n",
    "loss_val = th.function(\n",
    "    inputs=[x, label],\n",
    "    outputs=class_loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the gradient step size \n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate gradients with respect to the weights\n",
    "W1_grad = T.grad(class_loss, W1)\n",
    "b1_grad = T.grad(class_loss, b1)\n",
    "W2_grad = T.grad(class_loss, W2)\n",
    "b2_grad = T.grad(class_loss, b2)\n",
    "\n",
    "# Calculate updated values for the weights\n",
    "update_W1 = W1 - learning_rate * W1_grad\n",
    "update_b1 = b1 - learning_rate * b1_grad\n",
    "update_W2 = W2 - learning_rate * W2_grad\n",
    "update_b2 = b2 - learning_rate * b2_grad\n",
    "\n",
    "# Define updates\n",
    "updates = [\n",
    "    (W1, update_W1),\n",
    "    (b1, update_b1),\n",
    "    (W2, update_W2),\n",
    "    (b2, update_b2)\n",
    "]\n",
    "\n",
    "# Define train operation\n",
    "# - calculate loss\n",
    "# - update weights \n",
    "train_op = th.function(\n",
    "    inputs=[x, label],\n",
    "    outputs=class_loss,\n",
    "    updates=updates\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing data\n",
    "Xnorm = (xETC.values - xETC.values.mean(axis=0))/xETC.values.std(axis=0)\n",
    "XnormFull = (X.values - X.values.mean(axis=0))/X.values.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch = []\n",
    "AccuracyETC = []\n",
    "LossETC = []\n",
    "Accuracy = []\n",
    "Loss = []\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Accuracy: 0.5933670343137255\n",
      "Mean loss: 0.866911753478665\n",
      "\n",
      "Epoch: 1\n",
      "Accuracy: 0.68359375\n",
      "Mean loss: 0.7417362267773114\n",
      "\n",
      "Epoch: 2\n",
      "Accuracy: 0.7337622549019608\n",
      "Mean loss: 0.669085517371817\n",
      "\n",
      "Epoch: 3\n",
      "Accuracy: 0.7626378676470589\n",
      "Mean loss: 0.6194975688880048\n",
      "\n",
      "Epoch: 4\n",
      "Accuracy: 0.7838541666666666\n",
      "Mean loss: 0.5830545478405648\n",
      "\n",
      "Epoch: 5\n",
      "Accuracy: 0.7943474264705882\n",
      "Mean loss: 0.5549457891065406\n",
      "\n",
      "Epoch: 6\n",
      "Accuracy: 0.8013939950980392\n",
      "Mean loss: 0.5324385212681824\n",
      "\n",
      "Epoch: 7\n",
      "Accuracy: 0.8079044117647058\n",
      "Mean loss: 0.5138610385200418\n",
      "\n",
      "Epoch: 8\n",
      "Accuracy: 0.8133425245098039\n",
      "Mean loss: 0.498143102270396\n",
      "\n",
      "Epoch: 9\n",
      "Accuracy: 0.8178615196078431\n",
      "Mean loss: 0.48457392309008807\n",
      "\n",
      "CPU times: user 3h 57min 36s, sys: 35min 11s, total: 4h 32min 47s\n",
      "Wall time: 1h 54min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(epochs):\n",
    "    # Do training\n",
    "    for j in range(len(X)):\n",
    "        label = labels[j]\n",
    "        x_in = Xnorm[j]\n",
    "        _ = train_op(x_in, label)\n",
    "\n",
    "    # Do testing\n",
    "    n_correct = 0\n",
    "    loss_values = []\n",
    "    for j in range(len(X)):\n",
    "        label = labels[j]\n",
    "        x_in = Xnorm[j]\n",
    "        loss_values += [loss_val(x_in, label)]\n",
    "        answer = softmax_out(x_in)\n",
    "\n",
    "        n_correct += np.argmax(answer[0]) == label\n",
    "    print('Epoch:', i)\n",
    "    Epoch.append(i)\n",
    "    print('Accuracy:', n_correct / len(X))\n",
    "    AccuracyETC.append(n_correct / len(X))\n",
    "    print('Mean loss:', sum(loss_values) / len(X))\n",
    "    LossETC.append(sum(loss_values) / len(X))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Accuracy: 0.7868412990196079\n",
      "Mean loss: 0.5843286738493155\n",
      "\n",
      "Epoch: 1\n",
      "Accuracy: 0.8429074754901961\n",
      "Mean loss: 0.4420437923004798\n",
      "\n",
      "Epoch: 2\n",
      "Accuracy: 0.8711703431372549\n",
      "Mean loss: 0.3656098405143366\n",
      "\n",
      "Epoch: 3\n",
      "Accuracy: 0.889859068627451\n",
      "Mean loss: 0.3170276014283009\n",
      "\n",
      "Epoch: 4\n",
      "Accuracy: 0.9020373774509803\n",
      "Mean loss: 0.2834760876243834\n",
      "\n",
      "Epoch: 5\n",
      "Accuracy: 0.9109987745098039\n",
      "Mean loss: 0.2587471938425499\n",
      "\n",
      "Epoch: 6\n",
      "Accuracy: 0.9170496323529411\n",
      "Mean loss: 0.23950416525971802\n",
      "\n",
      "Epoch: 7\n",
      "Accuracy: 0.9220281862745098\n",
      "Mean loss: 0.22383058553777638\n",
      "\n",
      "Epoch: 8\n",
      "Accuracy: 0.9258578431372549\n",
      "Mean loss: 0.2105767324297736\n",
      "\n",
      "Epoch: 9\n",
      "Accuracy: 0.9298406862745098\n",
      "Mean loss: 0.1990337146867817\n",
      "\n",
      "CPU times: user 4h 59min 24s, sys: 46min 30s, total: 5h 45min 54s\n",
      "Wall time: 2h 16min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "for i in range(epochs):\n",
    "    # Do training\n",
    "    for j in range(len(X)):\n",
    "        label = labels[j]\n",
    "        x_in = XnormFull[j]\n",
    "        _ = train_op(x_in, label)\n",
    "\n",
    "    # Do testing\n",
    "    n_correct = 0\n",
    "    loss_values = []\n",
    "    for j in range(len(X)):\n",
    "        label = labels[j]\n",
    "        x_in = XnormFull[j]\n",
    "        loss_values += [loss_val(x_in, label)]\n",
    "        answer = softmax_out(x_in)\n",
    "\n",
    "        n_correct += np.argmax(answer[0]) == label\n",
    "    print('Epoch:', i)\n",
    "    print('Accuracy:', n_correct / len(X))\n",
    "    Accuracy.append(n_correct / len(X))\n",
    "    print('Mean loss:', sum(loss_values) / len(X))\n",
    "    Loss.append(sum(loss_values) / len(X))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb1f44e7ba8>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(Epoch,AccuracyETC,label='Accuracy')\n",
    "plt.plot(Epoch,LossETC,label='Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(\"10 features\")\n",
    "plt.legend(bbox_to_anchor=(1, 1),\n",
    "           bbox_transform=plt.gcf().transFigure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb1f46a90f0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Epoch,Accuracy,label='Accuracy')\n",
    "plt.plot(Epoch,Loss,label='Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.title(\"938 features\")\n",
    "plt.legend(bbox_to_anchor=(1, 1),\n",
    "           bbox_transform=plt.gcf().transFigure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Точность в предыдущей ЛР для 10 признаков составляла ~80%, в этой удалось увеличить до ~82%, используя 350 нейронов на скрытом уровне (10 эпоха). Для всех признаков из обучающего сета (938) удалось достигнуть точности в ~93% на 10 эпохе обучения.\n",
    "\n",
    "Выводы:\n",
    "+ точность возрастает при увеличении числа нейронов на скрытом уровне \n",
    "+ точность возрастает при увелчении кол-ва признаков\n",
    "- продолжительность обучения растет с повышением числа нейронов и признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
