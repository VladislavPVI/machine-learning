{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data and create DataFrame from it\n",
    "data = pd.read_csv('11.csv', sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>area</th>\n",
       "      <th>class</th>\n",
       "      <th>gray_Mean</th>\n",
       "      <th>gray_Variance</th>\n",
       "      <th>gray_Skewness</th>\n",
       "      <th>gray_Kurtosis</th>\n",
       "      <th>gray_Perc.01%</th>\n",
       "      <th>gray_Perc.10%</th>\n",
       "      <th>...</th>\n",
       "      <th>b_S(5,-5)SumVarnc</th>\n",
       "      <th>b_S(5,-5)SumEntrp</th>\n",
       "      <th>b_S(5,-5)Entropy</th>\n",
       "      <th>b_S(5,-5)DifVarnc</th>\n",
       "      <th>b_S(5,-5)DifEntrp</th>\n",
       "      <th>b_GrMean</th>\n",
       "      <th>b_GrVariance</th>\n",
       "      <th>b_GrSkewness</th>\n",
       "      <th>b_GrKurtosis</th>\n",
       "      <th>b_GrNonZeros</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>436697</td>\n",
       "      <td>22-Dec-2016 13-43-41</td>\n",
       "      <td>100</td>\n",
       "      <td>DZN</td>\n",
       "      <td>75.54</td>\n",
       "      <td>8.2884</td>\n",
       "      <td>-0.393290</td>\n",
       "      <td>-0.656038</td>\n",
       "      <td>68.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2901.143532</td>\n",
       "      <td>0.913105</td>\n",
       "      <td>1.420585</td>\n",
       "      <td>29.100282</td>\n",
       "      <td>0.867934</td>\n",
       "      <td>2.760527</td>\n",
       "      <td>2.676367</td>\n",
       "      <td>0.334689</td>\n",
       "      <td>-0.004993</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>436698</td>\n",
       "      <td>22-Dec-2016 13-43-41</td>\n",
       "      <td>100</td>\n",
       "      <td>DZN</td>\n",
       "      <td>67.59</td>\n",
       "      <td>14.0819</td>\n",
       "      <td>-0.367885</td>\n",
       "      <td>-1.074752</td>\n",
       "      <td>60.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2228.018342</td>\n",
       "      <td>0.950978</td>\n",
       "      <td>1.391802</td>\n",
       "      <td>6.977909</td>\n",
       "      <td>0.711356</td>\n",
       "      <td>3.481352</td>\n",
       "      <td>2.755186</td>\n",
       "      <td>-0.166114</td>\n",
       "      <td>-0.695810</td>\n",
       "      <td>0.953125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>436699</td>\n",
       "      <td>22-Dec-2016 13-43-41</td>\n",
       "      <td>100</td>\n",
       "      <td>DZN</td>\n",
       "      <td>60.86</td>\n",
       "      <td>5.3404</td>\n",
       "      <td>0.360231</td>\n",
       "      <td>-0.899669</td>\n",
       "      <td>57.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1910.459716</td>\n",
       "      <td>0.757815</td>\n",
       "      <td>1.315165</td>\n",
       "      <td>18.677696</td>\n",
       "      <td>0.819770</td>\n",
       "      <td>2.808814</td>\n",
       "      <td>2.735563</td>\n",
       "      <td>1.045370</td>\n",
       "      <td>1.092342</td>\n",
       "      <td>0.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>436700</td>\n",
       "      <td>22-Dec-2016 13-43-41</td>\n",
       "      <td>100</td>\n",
       "      <td>DZN</td>\n",
       "      <td>60.32</td>\n",
       "      <td>60.9776</td>\n",
       "      <td>-0.748717</td>\n",
       "      <td>-0.873833</td>\n",
       "      <td>44.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1700.315300</td>\n",
       "      <td>1.113652</td>\n",
       "      <td>1.626723</td>\n",
       "      <td>38.558999</td>\n",
       "      <td>1.015338</td>\n",
       "      <td>5.149898</td>\n",
       "      <td>6.853554</td>\n",
       "      <td>0.669685</td>\n",
       "      <td>-0.053380</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>436701</td>\n",
       "      <td>22-Dec-2016 13-43-41</td>\n",
       "      <td>100</td>\n",
       "      <td>DZN</td>\n",
       "      <td>75.00</td>\n",
       "      <td>5.2200</td>\n",
       "      <td>-0.090556</td>\n",
       "      <td>-0.474347</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2860.139183</td>\n",
       "      <td>0.738433</td>\n",
       "      <td>1.300173</td>\n",
       "      <td>16.376975</td>\n",
       "      <td>0.858845</td>\n",
       "      <td>2.469800</td>\n",
       "      <td>1.993839</td>\n",
       "      <td>0.061216</td>\n",
       "      <td>-0.683562</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 940 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                  name  area class  gray_Mean  gray_Variance  \\\n",
       "0      436697  22-Dec-2016 13-43-41   100   DZN      75.54         8.2884   \n",
       "1      436698  22-Dec-2016 13-43-41   100   DZN      67.59        14.0819   \n",
       "2      436699  22-Dec-2016 13-43-41   100   DZN      60.86         5.3404   \n",
       "3      436700  22-Dec-2016 13-43-41   100   DZN      60.32        60.9776   \n",
       "4      436701  22-Dec-2016 13-43-41   100   DZN      75.00         5.2200   \n",
       "\n",
       "   gray_Skewness  gray_Kurtosis  gray_Perc.01%  gray_Perc.10%      ...       \\\n",
       "0      -0.393290      -0.656038           68.0           71.0      ...        \n",
       "1      -0.367885      -1.074752           60.0           62.0      ...        \n",
       "2       0.360231      -0.899669           57.0           58.0      ...        \n",
       "3      -0.748717      -0.873833           44.0           47.0      ...        \n",
       "4      -0.090556      -0.474347           70.0           71.0      ...        \n",
       "\n",
       "   b_S(5,-5)SumVarnc  b_S(5,-5)SumEntrp  b_S(5,-5)Entropy  b_S(5,-5)DifVarnc  \\\n",
       "0        2901.143532           0.913105          1.420585          29.100282   \n",
       "1        2228.018342           0.950978          1.391802           6.977909   \n",
       "2        1910.459716           0.757815          1.315165          18.677696   \n",
       "3        1700.315300           1.113652          1.626723          38.558999   \n",
       "4        2860.139183           0.738433          1.300173          16.376975   \n",
       "\n",
       "   b_S(5,-5)DifEntrp  b_GrMean  b_GrVariance  b_GrSkewness  b_GrKurtosis  \\\n",
       "0           0.867934  2.760527      2.676367      0.334689     -0.004993   \n",
       "1           0.711356  3.481352      2.755186     -0.166114     -0.695810   \n",
       "2           0.819770  2.808814      2.735563      1.045370      1.092342   \n",
       "3           1.015338  5.149898      6.853554      0.669685     -0.053380   \n",
       "4           0.858845  2.469800      1.993839      0.061216     -0.683562   \n",
       "\n",
       "   b_GrNonZeros  \n",
       "0      0.906250  \n",
       "1      0.953125  \n",
       "2      0.984375  \n",
       "3      1.000000  \n",
       "4      0.906250  \n",
       "\n",
       "[5 rows x 940 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22-Dec-2016 13-43-41</td>\n",
       "      <td>DZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22-Dec-2016 13-43-41</td>\n",
       "      <td>DZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22-Dec-2016 13-43-41</td>\n",
       "      <td>DZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22-Dec-2016 13-43-41</td>\n",
       "      <td>DZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22-Dec-2016 13-43-41</td>\n",
       "      <td>DZN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name class\n",
       "0  22-Dec-2016 13-43-41   DZN\n",
       "1  22-Dec-2016 13-43-41   DZN\n",
       "2  22-Dec-2016 13-43-41   DZN\n",
       "3  22-Dec-2016 13-43-41   DZN\n",
       "4  22-Dec-2016 13-43-41   DZN"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['name', 'class']].head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('name', axis=1)\n",
    "y = data.loc[:, data.columns == 'class']\n",
    "x = data.loc[:, data.columns != 'class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DZN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class\n",
       "0   DZN\n",
       "1   DZN\n",
       "2   DZN\n",
       "3   DZN\n",
       "4   DZN"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>area</th>\n",
       "      <th>gray_Mean</th>\n",
       "      <th>gray_Variance</th>\n",
       "      <th>gray_Skewness</th>\n",
       "      <th>gray_Kurtosis</th>\n",
       "      <th>gray_Perc.01%</th>\n",
       "      <th>gray_Perc.10%</th>\n",
       "      <th>gray_Perc.50%</th>\n",
       "      <th>gray_Perc.90%</th>\n",
       "      <th>...</th>\n",
       "      <th>b_S(5,-5)SumVarnc</th>\n",
       "      <th>b_S(5,-5)SumEntrp</th>\n",
       "      <th>b_S(5,-5)Entropy</th>\n",
       "      <th>b_S(5,-5)DifVarnc</th>\n",
       "      <th>b_S(5,-5)DifEntrp</th>\n",
       "      <th>b_GrMean</th>\n",
       "      <th>b_GrVariance</th>\n",
       "      <th>b_GrSkewness</th>\n",
       "      <th>b_GrKurtosis</th>\n",
       "      <th>b_GrNonZeros</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>436697</td>\n",
       "      <td>100</td>\n",
       "      <td>75.54</td>\n",
       "      <td>8.2884</td>\n",
       "      <td>-0.393290</td>\n",
       "      <td>-0.656038</td>\n",
       "      <td>68.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2901.143532</td>\n",
       "      <td>0.913105</td>\n",
       "      <td>1.420585</td>\n",
       "      <td>29.100282</td>\n",
       "      <td>0.867934</td>\n",
       "      <td>2.760527</td>\n",
       "      <td>2.676367</td>\n",
       "      <td>0.334689</td>\n",
       "      <td>-0.004993</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>436698</td>\n",
       "      <td>100</td>\n",
       "      <td>67.59</td>\n",
       "      <td>14.0819</td>\n",
       "      <td>-0.367885</td>\n",
       "      <td>-1.074752</td>\n",
       "      <td>60.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2228.018342</td>\n",
       "      <td>0.950978</td>\n",
       "      <td>1.391802</td>\n",
       "      <td>6.977909</td>\n",
       "      <td>0.711356</td>\n",
       "      <td>3.481352</td>\n",
       "      <td>2.755186</td>\n",
       "      <td>-0.166114</td>\n",
       "      <td>-0.695810</td>\n",
       "      <td>0.953125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>436699</td>\n",
       "      <td>100</td>\n",
       "      <td>60.86</td>\n",
       "      <td>5.3404</td>\n",
       "      <td>0.360231</td>\n",
       "      <td>-0.899669</td>\n",
       "      <td>57.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1910.459716</td>\n",
       "      <td>0.757815</td>\n",
       "      <td>1.315165</td>\n",
       "      <td>18.677696</td>\n",
       "      <td>0.819770</td>\n",
       "      <td>2.808814</td>\n",
       "      <td>2.735563</td>\n",
       "      <td>1.045370</td>\n",
       "      <td>1.092342</td>\n",
       "      <td>0.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>436700</td>\n",
       "      <td>100</td>\n",
       "      <td>60.32</td>\n",
       "      <td>60.9776</td>\n",
       "      <td>-0.748717</td>\n",
       "      <td>-0.873833</td>\n",
       "      <td>44.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1700.315300</td>\n",
       "      <td>1.113652</td>\n",
       "      <td>1.626723</td>\n",
       "      <td>38.558999</td>\n",
       "      <td>1.015338</td>\n",
       "      <td>5.149898</td>\n",
       "      <td>6.853554</td>\n",
       "      <td>0.669685</td>\n",
       "      <td>-0.053380</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>436701</td>\n",
       "      <td>100</td>\n",
       "      <td>75.00</td>\n",
       "      <td>5.2200</td>\n",
       "      <td>-0.090556</td>\n",
       "      <td>-0.474347</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2860.139183</td>\n",
       "      <td>0.738433</td>\n",
       "      <td>1.300173</td>\n",
       "      <td>16.376975</td>\n",
       "      <td>0.858845</td>\n",
       "      <td>2.469800</td>\n",
       "      <td>1.993839</td>\n",
       "      <td>0.061216</td>\n",
       "      <td>-0.683562</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 938 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  area  gray_Mean  gray_Variance  gray_Skewness  gray_Kurtosis  \\\n",
       "0      436697   100      75.54         8.2884      -0.393290      -0.656038   \n",
       "1      436698   100      67.59        14.0819      -0.367885      -1.074752   \n",
       "2      436699   100      60.86         5.3404       0.360231      -0.899669   \n",
       "3      436700   100      60.32        60.9776      -0.748717      -0.873833   \n",
       "4      436701   100      75.00         5.2200      -0.090556      -0.474347   \n",
       "\n",
       "   gray_Perc.01%  gray_Perc.10%  gray_Perc.50%  gray_Perc.90%      ...       \\\n",
       "0           68.0           71.0           77.0           80.0      ...        \n",
       "1           60.0           62.0           68.0           71.0      ...        \n",
       "2           57.0           58.0           61.0           64.0      ...        \n",
       "3           44.0           47.0           64.0           68.0      ...        \n",
       "4           70.0           71.0           75.0           78.0      ...        \n",
       "\n",
       "   b_S(5,-5)SumVarnc  b_S(5,-5)SumEntrp  b_S(5,-5)Entropy  b_S(5,-5)DifVarnc  \\\n",
       "0        2901.143532           0.913105          1.420585          29.100282   \n",
       "1        2228.018342           0.950978          1.391802           6.977909   \n",
       "2        1910.459716           0.757815          1.315165          18.677696   \n",
       "3        1700.315300           1.113652          1.626723          38.558999   \n",
       "4        2860.139183           0.738433          1.300173          16.376975   \n",
       "\n",
       "   b_S(5,-5)DifEntrp  b_GrMean  b_GrVariance  b_GrSkewness  b_GrKurtosis  \\\n",
       "0           0.867934  2.760527      2.676367      0.334689     -0.004993   \n",
       "1           0.711356  3.481352      2.755186     -0.166114     -0.695810   \n",
       "2           0.819770  2.808814      2.735563      1.045370      1.092342   \n",
       "3           1.015338  5.149898      6.853554      0.669685     -0.053380   \n",
       "4           0.858845  2.469800      1.993839      0.061216     -0.683562   \n",
       "\n",
       "   b_GrNonZeros  \n",
       "0      0.906250  \n",
       "1      0.953125  \n",
       "2      0.984375  \n",
       "3      1.000000  \n",
       "4      0.906250  \n",
       "\n",
       "[5 rows x 938 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>area</th>\n",
       "      <th>gray_Mean</th>\n",
       "      <th>gray_Variance</th>\n",
       "      <th>gray_Skewness</th>\n",
       "      <th>gray_Kurtosis</th>\n",
       "      <th>gray_Perc.01%</th>\n",
       "      <th>gray_Perc.10%</th>\n",
       "      <th>gray_Perc.50%</th>\n",
       "      <th>gray_Perc.90%</th>\n",
       "      <th>...</th>\n",
       "      <th>b_S(5,-5)SumVarnc</th>\n",
       "      <th>b_S(5,-5)SumEntrp</th>\n",
       "      <th>b_S(5,-5)Entropy</th>\n",
       "      <th>b_S(5,-5)DifVarnc</th>\n",
       "      <th>b_S(5,-5)DifEntrp</th>\n",
       "      <th>b_GrMean</th>\n",
       "      <th>b_GrVariance</th>\n",
       "      <th>b_GrSkewness</th>\n",
       "      <th>b_GrKurtosis</th>\n",
       "      <th>b_GrNonZeros</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "      <td>13056.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>443224.500000</td>\n",
       "      <td>150.585784</td>\n",
       "      <td>96.254364</td>\n",
       "      <td>129.296636</td>\n",
       "      <td>-0.017162</td>\n",
       "      <td>0.280239</td>\n",
       "      <td>79.171262</td>\n",
       "      <td>85.588542</td>\n",
       "      <td>96.884344</td>\n",
       "      <td>105.803385</td>\n",
       "      <td>...</td>\n",
       "      <td>7583.373416</td>\n",
       "      <td>1.117667</td>\n",
       "      <td>1.674840</td>\n",
       "      <td>75.329206</td>\n",
       "      <td>0.946017</td>\n",
       "      <td>4.539982</td>\n",
       "      <td>7.800437</td>\n",
       "      <td>0.538672</td>\n",
       "      <td>0.076441</td>\n",
       "      <td>0.971969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3769.086892</td>\n",
       "      <td>54.714008</td>\n",
       "      <td>56.117444</td>\n",
       "      <td>266.620494</td>\n",
       "      <td>0.898016</td>\n",
       "      <td>2.438761</td>\n",
       "      <td>42.945108</td>\n",
       "      <td>48.626013</td>\n",
       "      <td>58.087830</td>\n",
       "      <td>61.667222</td>\n",
       "      <td>...</td>\n",
       "      <td>10411.572775</td>\n",
       "      <td>0.201292</td>\n",
       "      <td>0.227815</td>\n",
       "      <td>151.173722</td>\n",
       "      <td>0.195632</td>\n",
       "      <td>2.058940</td>\n",
       "      <td>10.905071</td>\n",
       "      <td>0.369186</td>\n",
       "      <td>1.011380</td>\n",
       "      <td>0.024650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>436697.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>34.630000</td>\n",
       "      <td>0.641900</td>\n",
       "      <td>-5.099406</td>\n",
       "      <td>-1.662739</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>21.886866</td>\n",
       "      <td>0.519481</td>\n",
       "      <td>0.929611</td>\n",
       "      <td>1.919168</td>\n",
       "      <td>0.442268</td>\n",
       "      <td>1.558813</td>\n",
       "      <td>0.570103</td>\n",
       "      <td>-0.589856</td>\n",
       "      <td>-1.458017</td>\n",
       "      <td>0.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>439960.750000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>54.239028</td>\n",
       "      <td>7.767127</td>\n",
       "      <td>-0.381784</td>\n",
       "      <td>-0.792883</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>693.818202</td>\n",
       "      <td>0.979165</td>\n",
       "      <td>1.518797</td>\n",
       "      <td>9.965087</td>\n",
       "      <td>0.802260</td>\n",
       "      <td>3.235369</td>\n",
       "      <td>3.053082</td>\n",
       "      <td>0.293227</td>\n",
       "      <td>-0.523740</td>\n",
       "      <td>0.958678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>443224.500000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>73.181187</td>\n",
       "      <td>20.001458</td>\n",
       "      <td>0.027967</td>\n",
       "      <td>-0.352191</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2427.906559</td>\n",
       "      <td>1.072661</td>\n",
       "      <td>1.648122</td>\n",
       "      <td>18.136813</td>\n",
       "      <td>0.900519</td>\n",
       "      <td>3.748919</td>\n",
       "      <td>4.047057</td>\n",
       "      <td>0.503083</td>\n",
       "      <td>-0.153380</td>\n",
       "      <td>0.975309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>446488.250000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>131.255682</td>\n",
       "      <td>73.262298</td>\n",
       "      <td>0.468372</td>\n",
       "      <td>0.338408</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11552.331860</td>\n",
       "      <td>1.221447</td>\n",
       "      <td>1.807004</td>\n",
       "      <td>58.661337</td>\n",
       "      <td>1.060938</td>\n",
       "      <td>5.087449</td>\n",
       "      <td>8.482724</td>\n",
       "      <td>0.733595</td>\n",
       "      <td>0.361828</td>\n",
       "      <td>0.988616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>449752.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>223.190000</td>\n",
       "      <td>1992.576737</td>\n",
       "      <td>4.031808</td>\n",
       "      <td>32.434843</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>52788.693309</td>\n",
       "      <td>1.873434</td>\n",
       "      <td>2.571574</td>\n",
       "      <td>1951.656937</td>\n",
       "      <td>1.650623</td>\n",
       "      <td>17.685676</td>\n",
       "      <td>172.929845</td>\n",
       "      <td>3.266544</td>\n",
       "      <td>15.479892</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 938 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0          area     gray_Mean  gray_Variance  \\\n",
       "count   13056.000000  13056.000000  13056.000000   13056.000000   \n",
       "mean   443224.500000    150.585784     96.254364     129.296636   \n",
       "std      3769.086892     54.714008     56.117444     266.620494   \n",
       "min    436697.000000    100.000000     34.630000       0.641900   \n",
       "25%    439960.750000    100.000000     54.239028       7.767127   \n",
       "50%    443224.500000    121.000000     73.181187      20.001458   \n",
       "75%    446488.250000    169.000000    131.255682      73.262298   \n",
       "max    449752.000000    400.000000    223.190000    1992.576737   \n",
       "\n",
       "       gray_Skewness  gray_Kurtosis  gray_Perc.01%  gray_Perc.10%  \\\n",
       "count   13056.000000   13056.000000   13056.000000   13056.000000   \n",
       "mean       -0.017162       0.280239      79.171262      85.588542   \n",
       "std         0.898016       2.438761      42.945108      48.626013   \n",
       "min        -5.099406      -1.662739      31.000000      33.000000   \n",
       "25%        -0.381784      -0.792883      48.000000      50.000000   \n",
       "50%         0.027967      -0.352191      65.000000      68.000000   \n",
       "75%         0.468372       0.338408     101.000000     112.000000   \n",
       "max         4.031808      32.434843     219.000000     220.000000   \n",
       "\n",
       "       gray_Perc.50%  gray_Perc.90%      ...       b_S(5,-5)SumVarnc  \\\n",
       "count   13056.000000   13056.000000      ...            13056.000000   \n",
       "mean       96.884344     105.803385      ...             7583.373416   \n",
       "std        58.087830      61.667222      ...            10411.572775   \n",
       "min        34.000000      37.000000      ...               21.886866   \n",
       "25%        54.000000      60.000000      ...              693.818202   \n",
       "50%        73.000000      79.000000      ...             2427.906559   \n",
       "75%       132.000000     147.000000      ...            11552.331860   \n",
       "max       223.000000     231.000000      ...            52788.693309   \n",
       "\n",
       "       b_S(5,-5)SumEntrp  b_S(5,-5)Entropy  b_S(5,-5)DifVarnc  \\\n",
       "count       13056.000000      13056.000000       13056.000000   \n",
       "mean            1.117667          1.674840          75.329206   \n",
       "std             0.201292          0.227815         151.173722   \n",
       "min             0.519481          0.929611           1.919168   \n",
       "25%             0.979165          1.518797           9.965087   \n",
       "50%             1.072661          1.648122          18.136813   \n",
       "75%             1.221447          1.807004          58.661337   \n",
       "max             1.873434          2.571574        1951.656937   \n",
       "\n",
       "       b_S(5,-5)DifEntrp      b_GrMean  b_GrVariance  b_GrSkewness  \\\n",
       "count       13056.000000  13056.000000  13056.000000  13056.000000   \n",
       "mean            0.946017      4.539982      7.800437      0.538672   \n",
       "std             0.195632      2.058940     10.905071      0.369186   \n",
       "min             0.442268      1.558813      0.570103     -0.589856   \n",
       "25%             0.802260      3.235369      3.053082      0.293227   \n",
       "50%             0.900519      3.748919      4.047057      0.503083   \n",
       "75%             1.060938      5.087449      8.482724      0.733595   \n",
       "max             1.650623     17.685676    172.929845      3.266544   \n",
       "\n",
       "       b_GrKurtosis  b_GrNonZeros  \n",
       "count  13056.000000  13056.000000  \n",
       "mean       0.076441      0.971969  \n",
       "std        1.011380      0.024650  \n",
       "min       -1.458017      0.828125  \n",
       "25%       -0.523740      0.958678  \n",
       "50%       -0.153380      0.975309  \n",
       "75%        0.361828      0.988616  \n",
       "max       15.479892      1.000000  \n",
       "\n",
       "[8 rows x 938 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>DZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        class\n",
       "count   13056\n",
       "unique      5\n",
       "top       DZN\n",
       "freq     3252"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Заметим, что у нас 5 уникальных классов. 5 + май = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'area', 'gray_Mean', 'gray_Variance', 'gray_Skewness',\n",
       "       'gray_Kurtosis', 'gray_Perc.01%', 'gray_Perc.10%', 'gray_Perc.50%',\n",
       "       'gray_Perc.90%',\n",
       "       ...\n",
       "       'b_S(5,-5)SumVarnc', 'b_S(5,-5)SumEntrp', 'b_S(5,-5)Entropy',\n",
       "       'b_S(5,-5)DifVarnc', 'b_S(5,-5)DifEntrp', 'b_GrMean', 'b_GrVariance',\n",
       "       'b_GrSkewness', 'b_GrKurtosis', 'b_GrNonZeros'],\n",
       "      dtype='object', length=938)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are several ways to do feature selection. \n",
    "# For this purpose sklearn provides SelectKBest class.\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "# Use feature importance field of the Extra Tree Classifier.\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_classif_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>g_Perc.90%</th>\n",
       "      <td>17646.539599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g_Perc.99%</th>\n",
       "      <td>17533.695049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gray_Perc.90%</th>\n",
       "      <td>16585.269447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gray_Perc.99%</th>\n",
       "      <td>16194.558560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gray_S(3,-3)SumAverg</th>\n",
       "      <td>14213.957720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gray_S(3,3)SumAverg</th>\n",
       "      <td>14157.915002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gray_S(4,-4)SumAverg</th>\n",
       "      <td>14154.311224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g_S(3,-3)SumAverg</th>\n",
       "      <td>14140.844337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gray_S(2,-2)SumAverg</th>\n",
       "      <td>14119.476909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gray_S(2,2)SumAverg</th>\n",
       "      <td>14099.986024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      f_classif_score\n",
       "g_Perc.90%               17646.539599\n",
       "g_Perc.99%               17533.695049\n",
       "gray_Perc.90%            16585.269447\n",
       "gray_Perc.99%            16194.558560\n",
       "gray_S(3,-3)SumAverg     14213.957720\n",
       "gray_S(3,3)SumAverg      14157.915002\n",
       "gray_S(4,-4)SumAverg     14154.311224\n",
       "g_S(3,-3)SumAverg        14140.844337\n",
       "gray_S(2,-2)SumAverg     14119.476909\n",
       "gray_S(2,2)SumAverg      14099.986024"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features = SelectKBest()\n",
    "fit = best_features.fit(x.values, y.values)\n",
    "# Create DataFrame from given data with given columns and indeces\n",
    "best_features = pd.DataFrame(data=fit.scores_, index=x.columns, columns=['f_classif_score'])\n",
    "# Sort rows by the absolute value\n",
    "best_features.nlargest(10, 'f_classif_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = ExtraTreesClassifier()\n",
    "model = model.fit(x.values, y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame from given data with given columns and indeces\n",
    "best_features = pd.DataFrame(data=model.feature_importances_, index=x.columns, columns=['feature_importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>g_S(3,-3)SumAverg</th>\n",
       "      <td>0.040689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b_S(1,0)SumVarnc</th>\n",
       "      <td>0.032645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_S(4,-4)SumVarnc</th>\n",
       "      <td>0.025623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b_Mean</th>\n",
       "      <td>0.024771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g_S(0,4)SumAverg</th>\n",
       "      <td>0.022845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gray_S(5,-5)SumAverg</th>\n",
       "      <td>0.019803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g_S(0,3)SumVarnc</th>\n",
       "      <td>0.018946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b_S(0,2)SumOfSqs</th>\n",
       "      <td>0.018944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b_S(3,0)SumVarnc</th>\n",
       "      <td>0.018254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_S(1,1)SumVarnc</th>\n",
       "      <td>0.017992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      feature_importance\n",
       "g_S(3,-3)SumAverg               0.040689\n",
       "b_S(1,0)SumVarnc                0.032645\n",
       "r_S(4,-4)SumVarnc               0.025623\n",
       "b_Mean                          0.024771\n",
       "g_S(0,4)SumAverg                0.022845\n",
       "gray_S(5,-5)SumAverg            0.019803\n",
       "g_S(0,3)SumVarnc                0.018946\n",
       "b_S(0,2)SumOfSqs                0.018944\n",
       "b_S(3,0)SumVarnc                0.018254\n",
       "r_S(1,1)SumVarnc                0.017992"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort rows by the absolute value\n",
    "best_features.nlargest(10, 'feature_importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Списки признаков\n",
    "xSKB = x.loc[:, ['g_Perc.90%','g_Perc.99%','gray_Perc.90%','gray_Perc.99%','gray_S(3,-3)SumAverg','gray_S(3,3)SumAverg','gray_S(4,-4)SumAverg','g_S(3,-3)SumAverg','gray_S(2,-2)SumAverg','gray_S(2,2)SumAverg']]\n",
    "xETC = x.loc[:, ['g_S(3,-3)SumAverg','b_S(1,0)SumVarnc','r_S(4,-4)SumVarnc','b_Mean','g_S(0,4)SumAverg','gray_S(5,-5)SumAverg','g_S(0,3)SumVarnc','b_S(0,2)SumOfSqs','b_S(3,0)SumVarnc','r_S(1,1)SumVarnc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a simple linear classifier trained using Stochastic Gradient Descent\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_norm = SGDClassifier(loss='log', penalty='l1', l1_ratio=1., alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "accurSKB = []\n",
    "accurETC = []\n",
    "countOfF = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "test = xSKB.iloc[:, :]\n",
    "countOfF.append(test.shape[1])\n",
    "scores = cross_val_score(model_norm,(test.values - test.values.mean(axis=0))/test.values.std(axis=0), y.values)\n",
    "accurSKB.append(scores.mean())\n",
    "test = xETC.iloc[:, :]\n",
    "scores = cross_val_score(model_norm,(test.values - test.values.mean(axis=0))/test.values.std(axis=0), y.values)\n",
    "accurETC.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/envs/jupyter_env/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,10,2):\n",
    "    test = xSKB.iloc[:, :-i]\n",
    "    countOfF.append(test.shape[1])\n",
    "    scores = cross_val_score(model_norm,(test.values - test.values.mean(axis=0))/test.values.std(axis=0), y.values)\n",
    "    accurSKB.append(scores.mean())\n",
    "    test = xETC.iloc[:, :-i]\n",
    "    scores = cross_val_score(model_norm,(test.values - test.values.mean(axis=0))/test.values.std(axis=0), y.values)\n",
    "    accurETC.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'SelectKBest')"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAfbUlEQVR4nO3de7wddX3u8c9jEiCKEpCNlSSFqEkAlSaeRbTSIoiYoB6Cl0JStWgV6usYL5ySHtLa0yOtthZPrVaqRbRiK6RIIaYeJVBAtBQ0O4ZbEgMhiuwEZXOJXMyRJDz9Y2bDyspsslbck7Uvz/v1Wq+95je/mfXdG7KfPb+Z+Y1sExER0epZ3S4gIiKGpwRERERUSkBERESlBERERFRKQERERKUEREREVEpARFSQZEkv6XYdEd2UgIhRTdJvSfpPST+X9JCkGyUds5c++9uS3tvStlPwSDpH0n2SXirpeElPSnqsfG2S9NEhqON4SX2/6n5i7ElAxKgl6XnAN4C/Aw4CJgMfBX7ZzboGSPoI8GHgNbbXlM2bbe9ve3/gt4D3SDq1a0XGmJaAiNFsBoDtS23vsL3V9tW2bwOQ9PuS1kl6WNIKSYdV7UTSvpI+Keknkn4m6fOSJjatny/pFkmPSLpb0jxJHwN+G/hseTTw2ZZ9/gXwXuA423dWfa7tHwH/CRzVtN0Rkq4pj4bWSzqtad0bJK2V9Gh59HGOpOcA3wIObToyOXTPfpwx1iQgYjS7E9gh6WJJJ0s6cGBF+Vf5HwNvAXqA7wKXDrKfT1CEzSzgJRRHIv+73M8c4CvAYmAScBzwY9t/Uu5zUXlEsKhpf38FnE4RDhsHK17SdOBY4OZy+TnANcAlwCHAQuDvJb203OSLwB/Yfi7wMuA6248DJ9N0ZGJ7825+bhFAAiJGMduPUAzTGPgC0C9puaQXAH8A/KXtdba3Ax8HZrUeRUgScCZwtu2HbD9a9l1QdnkP8CXb19h+0vYm2z/cTWmvB66y/ZOKdYdK2iLpEYqA+x7wH+W6N1GEzz/a3m77B8C/Am8r128DjpL0PNsPl+sj9lgCIka1MgDeZXsKxV/VhwJ/CxwGfLr8ZbwFeAgQxdFBsx7g2cCqpr5Xle0AU4G7OyxrAfC2QU5Ab7Y9yfbzKI5ItgIXl+sOA145UEdZy9uBXyvXvxV4A3CPpBsk/WaHdUXsZHy3C4jYW2z/UNKXKY4e7gU+Zvuru9nsAYpf0i+1vali/b3Aiwf7yEHa7wReB3xb0lbbfzVIvT+XdAnwL02fdYPtkwbpvxKYL2kCsAi4jCLAMmVz7JEcQcSoVZ7Q/UNJU8rlqRTj9jcDnweWDIzfSzpA0u+07sP2kxTDU5+SdEjZd7KkuWWXLwLvlnSipGeV644o1/0MeFFVbeVVS68DFkv68CD1709xtDFwhdM3gBmS3ilpQvk6RtKRkvaR9HZJB9jeBjwC7Giq4/mSDmjvJxdRSEDEaPYo8Erge5IepwiGO4A/tH0lxcnnpeV4/x0UJ3Or/C9gA3Bz2fffgZkAtr8PvBv4FPBz4AaKoSCAT1MMJT0s6TOtO7V9KzAX+DNJ7yubn7raCLiH4vLct5f9H6U4f7EA2Az8tPwe9i23fSfw47LG9wHvKLf7IcUJ+I3l0FSuYoq2KA8MioiIKjmCiIiISgmIiIiolICIiIhKCYiIiKg0au6DOPjgg3344Yd3u4yIiBFl1apVD9juqVo3agLi8MMPp7e3t9tlRESMKJLuGWxdhpgiIqJSAiIiIirVGhDlvPjrJW2QdG7F+k+V8+jfIunOcvIxJB0maVXZvqbpLtOIiNhLajsHIWkccAFwEtAHrJS03PbagT62z27q/wFgdrl4H/Bq278s56O5o9w289hHROwldR5BzAE22N5o+wlgKTD/GfovpHxgi+0nbA88FnLfmuuMiIgKdf7inUwxPfGAPnadax8ohpSAacB1TW1TJd1W7uMTVUcPks6S1Cupt7+/f0iLj4gY6+oMCFW0DTYz4ALgcts7nupo32v7aIpHPJ5RPgVs553ZF9pu2G709FRexhsREXuozoDoo3hYyYApFFMUV1nAIM8DLo8c1lA8AD4iIvaSOgNiJTBd0jRJ+1CEwPLWTpJmAgcCNzW1TZE0sXx/IMWD29fXWGtERLSo7Som29slLQJWAOMoHuy+RtJ5QK/tgbBYCCz1zg+mOBL4v5JMMVT1Sdu311VrRETsatQ8MKjRaDhTbUREdEbSKtuNqnW5fDQiIiolICIiolICIiIiKiUgIiKiUgIiIiIqJSAiIqJSAiIiIiolICIiolICIiIiKiUgIiKiUgIiIiIqJSAiIqJSAiIiIiolICIiolICIiIiKiUgIiKiUgIiIiIqJSAiIqJSAiIiIirVGhCS5klaL2mDpHMr1n9K0i3l605JW8r2WZJukrRG0m2STq+zzoiI2NX4unYsaRxwAXAS0AeslLTc9tqBPrbPbur/AWB2ufgL4Pds3yXpUGCVpBW2t9RVb0RE7KzOI4g5wAbbG20/ASwF5j9D/4XApQC277R9V/l+M3A/0FNjrRER0aLOgJgM3Nu03Fe27ULSYcA04LqKdXOAfYC7K9adJalXUm9/f/+QFB0REYU6A0IVbR6k7wLgcts7dtqB9ELgn4B3235yl53ZF9pu2G709OQAIyJiKNUZEH3A1KblKcDmQfouoBxeGiDpecD/Az5i++ZaKoyIiEHVGRArgemSpknahyIElrd2kjQTOBC4qaltH+BK4Cu2v1ZjjRERMYjaAsL2dmARsAJYB1xme42k8ySd0tR1IbDUdvPw02nAccC7mi6DnVVXrRERsSvt/Ht55Go0Gu7t7e12GRERI4qkVbYbVetyJ3VERFRKQERERKUEREREVEpAREREpdrmYoqIiHotW72J81esZ/OWrRw6aSKL587k1NmVE1bskQRERMQItGz1JpZccTtbtxUTUGzaspUlV9wOMGQhkSGmiIgR6PwV658KhwFbt+3g/BXrh+wzEhARESPQ5i1bO2rfEwmIiIgR6NBJEztq3xMJiIiIEWjx3JlMnDBup7aJE8axeO7MIfuMnKSOiBiBBk5E5yqmiIjYxamzJw9pILTKEFNERFRKQERERKUEREREVEpAREREpQRERERUylVMETFs1D35XHSm1iMISfMkrZe0QdK5Fes/1fTM6TslbWlad5WkLZK+UWeNETE8DEw+t2nLVszTk88tW72p26WNWbUFhKRxwAXAycBRwEJJRzX3sX227Vm2ZwF/B1zRtPp84J111RcRw8vemHwuOlPnEcQcYIPtjbafAJYC85+h/0Lg0oEF29cCj9ZYX0QMI3tj8rnoTJ0BMRm4t2m5r2zbhaTDgGnAdZ18gKSzJPVK6u3v79/jQiOi+/bG5HPRmToDQhVtHqTvAuBy2zsGWV/J9oW2G7YbPT09HRcYEcPH3ph8LjpT51VMfcDUpuUpwOZB+i4A3l9jLRExzO2NyeeiM3UGxEpguqRpwCaKEPjd1k6SZgIHAjfVWEtEjAB1Tz4XnaltiMn2dmARsAJYB1xme42k8ySd0tR1IbDU9k7DT5K+C3wNOFFSn6S5ddUaERG7Usvv5RGr0Wi4t7e322VERIwoklbZblSty1QbERFRKQERERGVEhAREVEpAREREZUSEBERUSkBERERlRIQERFRKQERERGVEhAREVEpAREREZUSEBERUSkBERERlRIQERFRKQERERGVEhAREVEpAREREZUSEBERUSkBERERlWoNCEnzJK2XtEHSuRXrPyXplvJ1p6QtTevOkHRX+TqjzjojImJX4+vasaRxwAXASUAfsFLScttrB/rYPrup/weA2eX7g4A/AxqAgVXltg/XVW9EROysziOIOcAG2xttPwEsBeY/Q/+FwKXl+7nANbYfKkPhGmBejbVGRESL3QaEpEWSDtyDfU8G7m1a7ivbqj7jMGAacF0n20o6S1KvpN7+/v49KDEiIgbTzhHEr1EMD11WnlNQm/uu6udB+i4ALre9o5NtbV9ou2G70dPT02ZZERHRjt0GhO2PANOBLwLvAu6S9HFJL97Npn3A1KblKcDmQfou4OnhpU63jYiIGrR1DsK2gZ+Wr+3AgcDlkv76GTZbCUyXNE3SPhQhsLy1k6SZ5f5uampeAbxe0oHl8Nbry7aIiNhLdnsVk6QPAmcADwAXAYttb5P0LOAu4I+qtrO9XdIiil/s44Av2V4j6Tyg1/ZAWCwElpYhNLDtQ5L+nCJkAM6z/dCefYsREbEn1PR7ubpD8Qv9i7bvqVh3pO11dRXXiUaj4d7e3m6XERExokhaZbtRta6dIaZvAk/99S7puZJeCTBcwiEiIoZeOwHxOeCxpuXHy7aIiBjF2gkItZwfeJIa78COiIjhoZ2A2Cjpg5ImlK8PARvrLiwiIrqrnYB4H/BqYBPF/QmvBM6qs6iIiOi+3Q4V2b6f4h6GiIgYQ9q5D2I/4D3AS4H9Btpt/36NdUVERJe1M8T0TxTzMc0FbqCY9uLROouKiIjuaycgXmL7T4HHbV8MvBF4eb1lRUREt7UTENvKr1skvQw4ADi8tooiImJYaOd+hgvLCfM+QjHZ3v7An9ZaVUREdN0zBkQ5Id8j5VPdvgO8aK9UFRERXfeMQ0zlXdOL9lItERExjLRzDuIaSedImirpoIFX7ZVFRERXtXMOYuB+h/c3tZkMN0VEjGrt3Ek9bW8UEhERw0s7d1L/XlW77a8MfTkRETFctDPEdEzT+/2AE4EfAAmIiIhRrJ0hpg80L0s6gGL6jYiIGMXauYqp1S+A6e10lDRP0npJGySdO0if0yStlbRG0iVN7Z+QdEf5On0P6oyIiF9BO+cg/o3iqiUoAuUo4LI2thsHXACcRPEciZWSltte29RnOrAEONb2w5IOKdvfCLwCmAXsC9wg6Vu2H+nkm4uIiD3XzjmITza93w7cY7uvje3mABtsbwSQtBSYD6xt6nMmcEF5p/bAsyegCKEbbG8Htku6FZhHG8EUERFDo50hpp8A37N9g+0bgQclHd7GdpOBe5uW+8q2ZjOAGZJulHSzpHll+63AyZKeLelg4ARgausHSDpLUq+k3v7+/jZKioiIdrUTEF8Dnmxa3lG27Y4q2tyyPJ7ifMbxwELgIkmTbF8NfBP4T+BS4CaKo5edd2ZfaLthu9HT09NGSRER0a52AmK87ScGFsr3+7SxXR87/9U/Bdhc0efrtrfZ/hGwnvIEuO2P2Z5l+ySKsLmrjc+MiIgh0k5A9Es6ZWBB0nzggTa2WwlMlzRN0j4Uz7Ve3tJnGcXwEeVQ0gxgo6Rxkp5fth8NHA1c3cZnRkTEEGnnJPX7gK9K+my53AdU3l3dzPZ2SYuAFcA44Eu210g6D+i1vbxc93pJaymGrhbbfrB8DvZ3JQE8AryjPGEdERF7iezW0wKDdJT2L/sPy+dRNxoN9/b2druMiIgRRdIq242qdbsdYpL08fLE8WO2H5V0oKS/GPoyIyJiOGnnHMTJtrcMLJT3LLyhvpIiImI4aCcgxknad2BB0kSKu5sjImIUa+ck9T8D10r6x3L53cDF9ZUUMXosW72J81esZ/OWrRw6aSKL587k1Nmt94tGDE/tzOb615JuA15HcT/CVcBhdRcWMdItW72JJVfcztZtOwDYtGUrS664HSAhESNCu7O5/pTibuq3UjwPYl1tFUWMEuevWP9UOAzYum0H569Y36WKIjoz6BGEpBkUN7ctBB4E/oXiMtcT9lJtESPa5i1bO2qPGG6eaYjph8B3gf9uewOApLP3SlUxbGVMvX2HTprIpoowOHTSxC5UE9G5ZxpieivF0NL1kr4g6USqJ+CLMWJgTH3Tlq2Yp8fUl63e1O3ShqXFc2cyccK4ndomThjH4rkzu1RRRGcGDQjbV9o+HTgC+DZwNvACSZ+T9Pq9VF8MIxlT78ypsyfzl295OZMnTUTA5EkT+cu3vDxHXDFitHMV0+PAVynmYzoI+B3gXDJ53piTMfXOnTp7cgIhRqyOnklt+yHb/2D7tXUVFMPXYGPnGVOPGJ06CogY2zKmHjG2tHMndQTw9M1duYopYmxIQERHMqYeMXZkiCkiIiolICIiolICIiIiKtUaEJLmSVovaYOkcwfpc5qktZLWSLqkqf2vy7Z1kj6j8gHVERGxd9R2klrSOOAC4CSgD1gpabnttU19pgNLgGNtPyzpkLL91cCxwNFl1/8AXkNxR3dEROwFdR5BzAE22N5o+wlgKTC/pc+ZwAXlY0yxfX/ZbmA/YB+Kp9dNAH5WY60REdGizoCYDNzbtNxXtjWbAcyQdKOkmyXNA7B9E3A9cF/5WmF7l2dQSDpLUq+k3v7+/lq+iYiIsarOgKg6Z+CW5fHAdOB4iudOXCRpkqSXAEcCUyhC5bWSjttlZ/aFthu2Gz09PUNafETEWFdnQPQBU5uWpwCbK/p83fY22z8C1lMExpuBm20/Zvsx4FvAq2qsNSIiWtQZECuB6ZKmSdqH4ul0y1v6LANOAJB0MMWQ00bgJ8BrJI2XNIHiBHUecxoRsRfVFhC2twOLgBUUv9wvs71G0nmSTim7rQAelLSW4pzDYtsPApcDdwO3A7cCt9r+t7pqjYiIXcluPS0wMjUaDff29na7jIiIEUXSKtuNqnW5kzoiIiolICIiolICIiIiKiUgIiKiUgIiIiIqJSAiIqJSAiIiIiolICIiolICIiIiKiUgIiKiUgIiIiIqJSAiIqJSAiIiIiolICIiolICIiIiKiUgIiKiUgIiIiIqje92Ad22bPUmzl+xns1btnLopIksnjuTU2dP7nZZERFdV+sRhKR5ktZL2iDp3EH6nCZpraQ1ki4p206QdEvT6/9LOnWo61u2ehNLrridTVu2YmDTlq0sueJ2lq3eNNQfFREx4tR2BCFpHHABcBLQB6yUtNz22qY+04ElwLG2H5Z0CIDt64FZZZ+DgA3A1UNd4/kr1rN1246d2rZu28H5K9bnKCIixrw6jyDmABtsb7T9BLAUmN/S50zgAtsPA9i+v2I/bwO+ZfsXQ13g5i1bO2qPiBhL6gyIycC9Tct9ZVuzGcAMSTdKulnSvIr9LAAurfoASWdJ6pXU29/f33GBh06a2FF7RMRYUmdAqKLNLcvjgenA8cBC4CJJk57agfRC4OXAiqoPsH2h7YbtRk9PT8cFLp47k4kTxu3UNnHCOBbPndnxviIiRps6r2LqA6Y2LU8BNlf0udn2NuBHktZTBMbKcv1pwJXl+iE3cJ4hVzFFROyqzoBYCUyXNA3YRDFU9LstfZZRHDl8WdLBFENOG5vWL6Q4iV2bU2dPTiBERFSobYjJ9nZgEcXw0DrgMttrJJ0n6ZSy2wrgQUlrgeuBxbYfBJB0OMURyA111RgREYOT3XpaYGRqNBru7e3tdhkRESOKpFW2G1XrMtVGRERUSkBERESlBERERFRKQERERKUEREREVEpAREREpQRERERUSkBERESlBERERFRKQERERKUEREREVEpAREREpQRERERUSkBERESlBERERFRKQERERKUEREREVEpAREREpQRERERUqjUgJM2TtF7SBknnDtLnNElrJa2RdElT+69LulrSunL94XXWGhEROxtf144ljQMuAE4C+oCVkpbbXtvUZzqwBDjW9sOSDmnaxVeAj9m+RtL+wJN11RoREbuq8whiDrDB9kbbTwBLgfktfc4ELrD9MIDt+wEkHQWMt31N2f6Y7V/UWGtERLSoMyAmA/c2LfeVbc1mADMk3SjpZknzmtq3SLpC0mpJ55dHJDuRdJakXkm9/f39tXwTERFjVZ0BoYo2tyyPB6YDxwMLgYskTSrbfxs4BzgGeBHwrl12Zl9ou2G70dPTM3SVR0RErQHRB0xtWp4CbK7o83Xb22z/CFhPERh9wOpyeGo7sAx4RY21RkREizoDYiUwXdI0SfsAC4DlLX2WAScASDqYYmhpY7ntgZIGDgteC6wlIiL2mtoCovzLfxGwAlgHXGZ7jaTzJJ1SdlsBPChpLXA9sNj2g7Z3UAwvXSvpdorhqi/UVWtEROxKdutpgZGp0Wi4t7e322VERIwoklbZblSty53UERFRKQERERGVEhAREVEpAREREZUSEBERUSkBERERlRIQERFRKQERERGVEhAREVEpAREREZUSEBERUSkBERERlRIQERFRadTM5iqpH7jnV9jFwcADQ1TOUEpdnUldnUldnRmNdR1mu/KRnKMmIH5VknoHm/K2m1JXZ1JXZ1JXZ8ZaXRliioiISgmIiIiolIB42oXdLmAQqaszqaszqaszY6qunIOIiIhKOYKIiIhKCYiIiKg05gNC0lRJ10taJ2mNpA91uyYASftJ+r6kW8u6PtrtmgZIGidptaRvdLuWZpJ+LOl2SbdI6u12PQCSJkm6XNIPy//HfnMY1DSz/BkNvB6R9OFu1wUg6ezy//c7JF0qab9u1wQg6UNlTWu6/bOS9CVJ90u6o6ntIEnXSLqr/HrgUHzWmA8IYDvwh7aPBF4FvF/SUV2uCeCXwGtt/wYwC5gn6VVdrmnAh4B13S5iECfYnjWMrlX/NHCV7SOA32AY/Nxsry9/RrOA/wb8Ariyy2UhaTLwQaBh+2XAOGBBd6sCSS8DzgTmUPw3fJOk6V0s6cvAvJa2c4FrbU8Hri2Xf2VjPiBs32f7B+X7Ryn+AU/ublXgwmPl4oTy1fUrCiRNAd4IXNTtWoY7Sc8DjgO+CGD7CdtbulvVLk4E7rb9q8xCMJTGAxMljQeeDWzucj0ARwI32/6F7e3ADcCbu1WM7e8AD7U0zwcuLt9fDJw6FJ815gOimaTDgdnA97pbSaEcyrkFuB+4xvZwqOtvgT8Cnux2IRUMXC1plaSzul0M8CKgH/jHckjuIknP6XZRLRYAl3a7CADbm4BPAj8B7gN+bvvq7lYFwB3AcZKeL+nZwBuAqV2uqdULbN8HxR+9wCFDsdMEREnS/sC/Ah+2/Ui36wGwvaMcBpgCzCkPdbtG0puA+22v6mYdz+BY268ATqYYKjyuy/WMB14BfM72bOBxhujQfyhI2gc4Bfhat2sBKMfN5wPTgEOB50h6R3erAtvrgE8A1wBXAbdSDE2PegkIQNIEinD4qu0rul1Pq3JY4tvsOu64tx0LnCLpx8BS4LWS/rm7JT3N9uby6/0UY+pzulsRfUBf05Hf5RSBMVycDPzA9s+6XUjpdcCPbPfb3gZcAby6yzUBYPuLtl9h+ziK4Z27ul1Ti59JeiFA+fX+odjpmA8ISaIYI15n+2+6Xc8AST2SJpXvJ1L84/lhN2uyvcT2FNuHUwxNXGe763/hAUh6jqTnDrwHXk8xNNA1tn8K3CtpZtl0IrC2iyW1WsgwGV4q/QR4laRnl/8uT2QYnNQHkHRI+fXXgbcwvH5uAMuBM8r3ZwBfH4qdjh+KnYxwxwLvBG4vx/sB/tj2N7tYE8ALgYsljaMI8stsD6vLSoeZFwBXFr9XGA9cYvuq7pYEwAeAr5bDORuBd3e5HgDKsfSTgD/odi0DbH9P0uXADyiGcFYzfKa2+FdJzwe2Ae+3/XC3CpF0KXA8cLCkPuDPgL8CLpP0Hoqg/Z0h+axMtREREVXG/BBTRERUS0BERESlBERERFRKQERERKUEREREVEpAxIgl6dckLZV0t6S1kr4pacYQf8bxkjq6WUvSvpL+vZwp9fSWdUeU7aslvXgP6vlweYlqRO0SEDEilTdSXQl82/aLbR8F/DHF/RBD6Xg6v5t3NjChnDH1X1rWnQp83fZs23fvQT0fppjErm3lxHcRHUtAxEh1ArDN9ucHGmzfYvu7Kpxfzt9/+8Bf8eXRwFM3G0r6rKR3le9/LOmjkn5QbnNEOXnj+4Czy7/6f7u5gHIO/mWSbpN0s6Sjyztu/xmYVW7z4qb+b6D4Bf9eSdeXbe9Q8dyPWyT9Q3ljJJI+J6lXTc8CkfRBijmKrm/a/rGm/b9N0pfL91+W9Ddlv0+Ud5p/SdLK8uhlftnvpU2ff5u6O411DDP5yyJGqpcBg00a+BaKZ2j8BnAwsFLSd9rY5wO2XyHpfwDn2H6vpM8Dj9n+ZEX/jwKrbZ8q6bXAV2zPkvTecvs3NXe2/c3m/Uk6EjidYpLBbZL+Hng78BXgT2w/VAbGtZKOtv0ZSf+T4pkXD7Tx/cwAXmd7h6SPU0yN8vvlFC7fl/TvFAH4adsDd3uPa2O/MUYkIGI0+i3gUts7KCYxuwE4BtjdLL0DEzWuogiZdj7nrQC2r1MxHfQBHdR5IsUDe1aWU4RM5OlJ1k5TMWX5eIppV44Cbutg3wBfK38GUMxNdYqkc8rl/YBfB24C/kTFcz6usD3cJqGLLkpAxEi1BnjbIOs0SPt2dh5WbX2c5S/Lrzto799G1ed0MneNgIttL9mpUZoGnAMcY/vhcthosEdvNn9ea5/HWz7rrbbXt/RZJ+l7FA+BWiHpvbav6+B7iFEs5yBipLoO2FfSmQMNko6R9BrgO8DpKh641EPxVLfvA/cAR5VXGR1A8Rf87jwKPHeQdd+hGBJC0vEUQ1SdPEvkWuBtTTOFHiTpMOB5FL/cfy7pBRTTcg9Wz88kHSnpWTzzU85WAB8oT+4jaXb59UXARtufoZgR9OgO6o9RLgERI5KLWSbfDJxUXua6Bvg/FI+ovJJiOOZWiiD5I9s/tX0vcFm57qsUs4Xuzr8Bb646SV1+XkPSbRSzaZ7RuvFuvoe1wEconoJ3G8UDaV5o+9aytjXAl4Abmza7EPjWwElqigcQfaP8Pu97ho/7c4rH1t6m4mH3f162nw7coWIm4yMozn9EAJnNNSIiBpEjiIiIqJSAiIiISgmIiIiolICIiIhKCYiIiKiUgIiIiEoJiIiIqPRf1FIh7Ppx8ukAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(countOfF,accurSKB)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Count of features\")\n",
    "plt.title(\"SelectKBest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Extra Tree Classifier')"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(countOfF,accurETC)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Count of features\")\n",
    "plt.title(\"Extra Tree Classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы: при поиске значимых признаков с помощью SelectKBest преобладают g_Perc и SumAverg, а при поиске с помощью ExtraTreesClassifier преобладают SumVarnc и SumAverg. Точность классификации выше при использовании признаков Extra Tree Classifier. С уменьшением числа признаков происходит уменьшение точности классификации.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
